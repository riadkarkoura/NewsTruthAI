import streamlit as st
import requests
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from deep_translator import GoogleTranslator
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import csv

nltk.download('stopwords')

translator = GoogleTranslator(source='auto', target='en')
analyzer = SentimentIntensityAnalyzer()

stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    words = text.split()
    words = [word for word in words if word not in stop_words]
    words = [stemmer.stem(word) for word in words]
    return ' '.join(words)

def get_latest_news(api_key, query="news", language="en", page_size=5):
    url = (
        'https://newsapi.org/v2/everything?'
        f'q={query}&'
        f'language={language}&'
        f'pageSize={page_size}&'
        'sortBy=publishedAt&'
        f'apiKey={api_key}'
    )
    response = requests.get(url)
    data = response.json()
    if data['status'] == 'ok':
        articles = data['articles']
        return [article['title'] + ". " + article.get('description', '') for article in articles]
    else:
        st.error("Error fetching news: " + data.get('message', 'Unknown error'))
        return []

def classify_text_with_vader(text):
    try:
        translated = translator.translate(text)
        scores = analyzer.polarity_scores(translated)
        compound = scores['compound']
        # Ø§Ø°Ø§ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…ÙˆØ¬Ø¨Ø© ÙÙ‡ÙŠ Ø§ÙŠØ¬Ø§Ø¨ÙŠØ© (Ø®Ø¨Ø± Ø­Ù‚ÙŠÙ‚ÙŠ)ØŒ Ø§Ø°Ø§ Ø³Ø§Ù„Ø¨Ø© ÙÙ‡ÙŠ Ø®Ø¨Ø± ÙƒØ§Ø°Ø¨
        if compound >= 0.05:
            label = "Ø®Ø¨Ø± Ø­Ù‚ÙŠÙ‚ÙŠ âœ…"
        elif compound <= -0.05:
            label = "Ø®Ø¨Ø± ÙƒØ§Ø°Ø¨ âŒ"
        else:
            label = "Ø®Ø¨Ø± ØºÙŠØ± ÙˆØ§Ø¶Ø­ ðŸ¤”"
        return label, translated, compound
    except Exception as e:
        return f"Error: {str(e)}", "", 0

def save_feedback(news, predicted_label, feedback):
    with open("feedback.csv", "a", newline='', encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([news, predicted_label, feedback])

st.set_page_config(page_title="NewsTruth AI", layout="wide")
st.title("ðŸ“° NewsTruth AI â€“ ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©")

api_key = st.text_input("ðŸ”‘ Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ NewsAPI Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ:", value="", type="password")

if api_key:
    query = st.text_input("ðŸ” Ø§ÙƒØªØ¨ ÙƒÙ„Ù…Ø© Ø¨Ø­Ø« (Ù…Ø«Ø§Ù„: Ø³ÙˆØ±ÙŠØ§ØŒ Ø³ÙŠØ§Ø³Ø©ØŒ Ù„Ù‚Ø§Ø­):", value="Syria OR vaccine")

    if st.button("ðŸ“¡ Ø¬Ù„Ø¨ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø­Ø¯ÙŠØ«Ø©"):
        lang = "ar" if any('\u0600' <= c <= '\u06FF' for c in query) else "en"
        news_items = get_latest_news(api_key, query=query, language=lang, page_size=5)

        st.subheader("ðŸ—žï¸ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ØµÙ†ÙØ©:")
        for i, news in enumerate(news_items, 1):
            label, translated, score = classify_text_with_vader(news)

            st.markdown(f"**{i}. Ø§Ù„Ø®Ø¨Ø±:** {news}")
            if translated:
                st.markdown(f"*Ø§Ù„ØªØ±Ø¬Ù…Ø©:* {translated}")
            st.markdown(f"ðŸ”Ž **Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {label} (Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: {score:.2f})")

            col1, col2 = st.columns(2)
            with col1:
                if st.button(f"âœ… Ø§Ù„ØªØµÙ†ÙŠÙ ØµØ­ÙŠØ­ (Ø®Ø¨Ø± {i})"):
                    save_feedback(news, label, "correct")
                    st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙƒØªØµÙ†ÙŠÙ ØµØ­ÙŠØ­.")
            with col2:
                if st.button(f"âŒ Ø§Ù„ØªØµÙ†ÙŠÙ Ø®Ø§Ø·Ø¦ (Ø®Ø¨Ø± {i})"):
                    save_feedback(news, label, "wrong")
                    st.warning("ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙƒØªØµÙ†ÙŠÙ Ø®Ø§Ø·Ø¦.")
            st.write("---")

    st.subheader("âœï¸ ØªØµÙ†ÙŠÙ Ø®Ø¨Ø± Ø¹Ø±Ø¨ÙŠ ÙŠØ¯ÙˆÙŠ:")
    user_input = st.text_area("Ø£Ø¯Ø®Ù„ Ù†Øµ Ø§Ù„Ø®Ø¨Ø± Ù‡Ù†Ø§:")

    if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨Ø±"):
        if user_input.strip():
            label, translated, score = classify_text_with_vader(user_input)
            st.markdown(f"**ðŸ”„ Ø§Ù„ØªØ±Ø¬Ù…Ø©:** {translated}")
            st.markdown(f"**ðŸ” Ø§Ù„ØªØµÙ†ÙŠÙ:** {label} (Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: {score:.2f})")

            col1, col2 = st.columns(2)
            with col1:
                if st.button("âœ… Ø§Ù„ØªØµÙ†ÙŠÙ ØµØ­ÙŠØ­ (Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ÙŠØ¯ÙˆÙŠ)"):
                    save_feedback(user_input, label, "correct")
                    st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙƒØªØµÙ†ÙŠÙ ØµØ­ÙŠØ­.")
            with col2:
                if st.button("âŒ Ø§Ù„ØªØµÙ†ÙŠÙ Ø®Ø§Ø·Ø¦ (Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ÙŠØ¯ÙˆÙŠ)"):
                    save_feedback(user_input, label, "wrong")
                    st.warning("ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙƒØªØµÙ†ÙŠÙ Ø®Ø§Ø·Ø¦.")
        else:
            st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹.")

st.sidebar.markdown("## ðŸ‘¤ Riad Karkoura")
st.sidebar.markdown("ØµØ­ÙÙŠ ØªÙ‚Ù†ÙŠ | Ù…Ø®ØªØµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø±")
st.sidebar.markdown("[ðŸ”— LinkedIn](https://www.linkedin.com/in/riad-karkoura-b9010b196)")
